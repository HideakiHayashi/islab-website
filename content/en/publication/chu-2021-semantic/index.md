---
# Documentation: https://sourcethemes.com/academic/docs/managing-content/

title: The semantic typology of visually grounded paraphrases
subtitle: ''
summary: ''
authors:
- Chenhui Chu
- Vinicius Oliveira
- Felix Giovanni Virgo
- Mayu Otani
- Noa Garcia
- Yuta Nakashima
tags: []
categories: []
date: '2021-12-01'
lastmod: 2022-09-05T16:51:44+09:00
featured: false
draft: false

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder.
# Focal points: Smart, Center, TopLeft, Top, TopRight, Left, Right, BottomLeft, Bottom, BottomRight.
image:
  caption: ''
  focal_point: ''
  preview_only: false

# Projects (optional).
#   Associate this post with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `projects = ["internal-project"]` references `content/project/deep-learning/index.md`.
#   Otherwise, set `projects = []`.
projects: []
publishDate: '2022-09-05T07:51:44.797083Z'
publication_types:
- '2'
abstract: Visually grounded paraphrases (VGPs) are different phrasal expressions describing
  the same visual concept in an image. Previous studies treat VGP identification as
  a binary classification task, which ignores various phenomena behind VGPs (i.e.,
  different linguistic interpretation of the same visual concept) such as linguistic
  paraphrases and VGPs from different aspects. In this paper, we propose semantic
  typology for VGPs, aiming to elucidate the VGP phenomena and deepen the understanding
  about how human beings interpret vision with language. We construct a large VGP
  dataset that annotates the class to which each VGP pair belongs according to our
  typology. In addition, we present a classification model that fuses language and
  visual features for VGP classification on our dataset. Experiments indicate that
  joint language and vision representation learning is important for VGP classification.
  We further demonstrate that our VGP typology can boost the performance of visually
  grounded textual entailment.
publication: '*Computer Vision and Image Understanding*'
doi: https://doi.org/10.1016/j.cviu.2021.103333
links:
- name: URL
  url: https://www.sciencedirect.com/science/article/pii/S1077314221001697
---
